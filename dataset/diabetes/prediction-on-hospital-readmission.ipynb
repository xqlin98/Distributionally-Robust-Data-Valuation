{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8459f4e9e52473b4fe8824724a87798e1946e02"
   },
   "source": [
    "# Data Preparation & Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f159da396824602d8ae73fc5cb08f84987ce91f6"
   },
   "outputs": [],
   "source": [
    "#Loading libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2d61c7050ae4bf21dd0c5e84949ed951483312d"
   },
   "outputs": [],
   "source": [
    "#loading Dataset\n",
    "df = pd.read_csv(\"./diabetic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06c7f80de93a3640a4cdaafc392374cdaf3d4e23"
   },
   "outputs": [],
   "source": [
    "#displaying first 10 rows of data\n",
    "df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3bdb38381d0dfc06aab75ff81c0dc59287ce470f"
   },
   "outputs": [],
   "source": [
    "#checking shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "169448129042f3eba5d3d406bf84f04a11a722d3"
   },
   "outputs": [],
   "source": [
    "#Checking data types of each variable\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fda696aba45c9a0638e4dcf95c292aeba37f0f14"
   },
   "outputs": [],
   "source": [
    "#Checking for missing values in dataset\n",
    "#In the dataset missing values are represented as '?' sign\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "         print(col,df[col][df[col] == '?'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d048d16f638808017b8f95345920cdcec6dc9ff5"
   },
   "outputs": [],
   "source": [
    "# gender was coded differently so we use a custom count for this one            \n",
    "print('gender', df['gender'][df['gender'] == 'Unknown/Invalid'].count())            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e22d1a4d0030454d23ae88722b3030dcbb0b540"
   },
   "source": [
    "## Dealing with Missing Values\n",
    "Variable weight contains approximate 98% of the missing values so there is no significance in filling those missing values so we decided to drop these variables. Variable Payer code and medical specialty contains approximate 40% missing values so we also dropped these variables. Variables race, diag_1, diag_2, diag_3 and gender contains very less missing values as compared to other attributes which we dropped so for these attributes we also decided to drop those where missing values contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6edaf833116f062e8b729403b2f1bc871fa7c3ff"
   },
   "outputs": [],
   "source": [
    "#dropping columns with large number of missing values\n",
    "df = df.drop(['weight','payer_code','medical_specialty'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7934d84f6119a0d5e524b8d8250a143f6de87bc"
   },
   "outputs": [],
   "source": [
    "drop_Idx = set(df[(df['diag_1'] == '?') & (df['diag_2'] == '?') & (df['diag_3'] == '?')].index)\n",
    "\n",
    "drop_Idx = drop_Idx.union(set(df['diag_1'][df['diag_1'] == '?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_2'][df['diag_2'] == '?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_3'][df['diag_3'] == '?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['race'][df['race'] == '?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df[df['discharge_disposition_id'] == 11].index))\n",
    "drop_Idx = drop_Idx.union(set(df['gender'][df['gender'] == 'Unknown/Invalid'].index))\n",
    "new_Idx = list(set(df.index) - set(drop_Idx))\n",
    "df = df.iloc[new_Idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "930d7a144498a9fabd43d9de775dcd30b76b70c5"
   },
   "source": [
    "variables (drugs named citoglipton and examide), all records have the same value. So essentially these cannot provide any interpretive or discriminatory information for predicting readmission so we decided to drop these two variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c61817d428256fe7dbc6fc4268585a54fc3d5463"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['citoglipton', 'examide'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92231506c0a8f53dddc12d4065db0329ac538a5b"
   },
   "outputs": [],
   "source": [
    "#Checking for missing values in the data\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "         print(col,df[col][df[col] == '?'].count())\n",
    "            \n",
    "print('gender', df['gender'][df['gender'] == 'Unknown/Invalid'].count())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is highly subjective, and partly depends on a knowledge of health care services, and making sense of the potential relationships between features. There are perhaps thousands of ways to try here. We tried some...\n",
    "\n",
    "* Service utilization: The data contains variables for number of inpatient (admissions), emergency room visits and outpatient visits for a given patient in the previous one year. These are (crude) measures of how much hospital/clinic services a person has used in the past year. We added these three to create a new variable called service utilization (see figure below). The idea was to see which version gives us better results. Granted, we did not apply any special weighting to the three ingredients of service utilization but we wanted to try something simple at this stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['service_utilization'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of medication changes: The dataset contains 23 features for 23 drugs (or combos) which indicate for each of these, whether a change in that medication was made or not during the current hospital stay of patient. Medication change for diabetics upon admission has been shown by previous research to be associated with lower readmission rates. We decided to count how many changes were made in total for each patient, and declared that a new feature. The reasoning here was to both simplify the model and possibly discover a relationship with number of changes regardless of which drug was changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', 'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "for col in keys:\n",
    "    colname = str(col) + 'temp'\n",
    "    df[colname] = df[col].apply(lambda x: 0 if (x == 'No' or x == 'Steady') else 1)\n",
    "df['numchange'] = 0\n",
    "for col in keys:\n",
    "    colname = str(col) + 'temp'\n",
    "    df['numchange'] = df['numchange'] + df[colname]\n",
    "    del df[colname]\n",
    "    \n",
    "df['numchange'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-encoding admission type, discharge type and admission source into fewer categories\n",
    "\n",
    "df['admission_type_id'] = df['admission_type_id'].replace(2,1)\n",
    "df['admission_type_id'] = df['admission_type_id'].replace(7,1)\n",
    "df['admission_type_id'] = df['admission_type_id'].replace(6,5)\n",
    "df['admission_type_id'] = df['admission_type_id'].replace(8,5)\n",
    "\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(6,1)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(8,1)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(9,1)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(13,1)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(3,2)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(4,2)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(5,2)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(14,2)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(22,2)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(23,2)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(24,2)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(12,10)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(15,10)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(16,10)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(17,10)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(25,18)\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(26,18)\n",
    "\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(2,1)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(3,1)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(5,4)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(6,4)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(10,4)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(22,4)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(25,4)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(15,9)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(17,9)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(20,9)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(21,9)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(13,11)\n",
    "df['admission_source_id'] = df['admission_source_id'].replace(14,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Encoding some variables: The original dataset used string values for gender, race, medication change, and each of the 23 drugs used. To better fit those variables into our model, we interpret the variables to numeric binary variables to reflect their nature. For example, we encoded the “ medication change ” feature from “No” (no change) and “Ch” (changed) into 0 and 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['change'] = df['change'].replace('Ch', 1)\n",
    "df['change'] = df['change'].replace('No', 0)\n",
    "df['gender'] = df['gender'].replace('Male', 1)\n",
    "df['gender'] = df['gender'].replace('Female', 0)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('Yes', 1)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('No', 0)\n",
    "# keys is the same as before\n",
    "for col in keys:\n",
    "    df[col] = df[col].replace('No', 0)\n",
    "    df[col] = df[col].replace('Steady', 1)\n",
    "    df[col] = df[col].replace('Up', 1)\n",
    "    df[col] = df[col].replace('Down', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also reduced both A1C test result and Glucose serum test result into categories of Normal, Abnormal and Not tested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A1Cresult'] = df['A1Cresult'].replace('>7', 1)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('>8', 1)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('Norm', 0)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('None', -99)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('>200', 1)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('>300', 1)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('Norm', 0)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('None', -99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dealing with age: There are different ways to deal with this. The dataset only gives us age as 10 year categories, so we don’t know the exact age of each patient. The previous study on this dataset used age categories as nominal variables, but we wanted to be able to see the effect of increasing age on readmission, even if in a crude way. To do that, we assume that age of the patient on average lies at the midpoint of the age category. For example, if the patient’s age category is 20–30 years, then we assume the age = 25 years. So we converted age categories to midpoints, resulting in a numeric variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code age intervals [0-10) - [90-100) from 1-10\n",
    "for i in range(0,10):\n",
    "    df['age'] = df['age'].replace('['+str(10*i)+'-'+str(10*(i+1))+')', i+1)\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collapsing of Multiple Encounters for same patient Some patients in the dataset had more than one encounter.We could not count them as independent encounters because that bias the results towards those patients who had multiple encounters. Thus we tried multiple techniques to collapse and consolidate multiple encounters for same patient such as:\n",
    "\n",
    "* Considering more than 2 readmissions across multiple encounters as readmission for collapsed record.\n",
    "* Considering average stay at hospital across multiple encounters.\n",
    "* Considering the percentage of the medication changes across multiple encounters\n",
    "* Considering the total number of the encounters to replace the encounter unique ID\n",
    "* Considering the combination of diagnoses across multiple encounters as a list However, taking the features such as “diagnosis”, for instance, we did not find it not meaningful to combine multiple categorical values into an array for building data model. We then considered first encounter and last encounter separately as possible representations of multiple encounters. However, last encounters gave extremely imbalanced data for readmissions (96/4 Readmissions vs No Readmissions) and thus, we decided to use first encounters of patients with multiple encounters. This resulted in dataset being reduced to about 70,000 encounters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop_duplicates(subset= ['patient_nbr'], keep = 'first')\n",
    "df2.shape\n",
    "(70442, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Encoding the outcome variable: The outcome we are looking at is whether the patient gets readmitted to the hospital within 30 days or not. The variable actually has < 30, > 30 and No Readmission categories. To reduce our problem to a binary classification, we combined the readmission after 30 days and no readmission into a single category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'] = df['readmitted'].replace('>30', 0)\n",
    "df['readmitted'] = df['readmitted'].replace('<30', 1)\n",
    "df['readmitted'] = df['readmitted'].replace('NO', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorization of diagnoses: The dataset contained up to three diagnoses for a given patient (primary, secondary and additional). However, each of these had 700–900 unique ICD codes and it is extremely difficult to include them in the model and interpret meaningfully. Therefore, we collapsed these diagnosis codes into 9 disease categories in an almost similar fashion to that done in the original publication using this dataset. These 9 categories include Circulatory, Respiratory, Digestive, Diabetes, Injury, Musculoskeletal, Genitourinary, Neoplasms, and Others. Although we did this for primary, secondary and additional diagnoses, we eventually decided to use only the primary diagnosis in our model. Doing this in python was slightly cumbersome because, well, we are mapping the disease codes to certain category names. Below code should demonstrate this easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating additional columns for diagnosis# Creati \n",
    "df['level1_diag1'] = df['diag_1']\n",
    "df['level2_diag1'] = df['diag_1']\n",
    "df['level1_diag2'] = df['diag_2']\n",
    "df['level2_diag2'] = df['diag_2']\n",
    "df['level1_diag3'] = df['diag_3']\n",
    "df['level2_diag3'] = df['diag_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['diag_1'].str.contains('V'), ['level1_diag1', 'level2_diag1']] = 0\n",
    "df.loc[df['diag_1'].str.contains('E'), ['level1_diag1', 'level2_diag1']] = 0\n",
    "df.loc[df['diag_2'].str.contains('V'), ['level1_diag2', 'level2_diag2']] = 0\n",
    "df.loc[df['diag_2'].str.contains('E'), ['level1_diag2', 'level2_diag2']] = 0\n",
    "df.loc[df['diag_3'].str.contains('V'), ['level1_diag3', 'level2_diag3']] = 0\n",
    "df.loc[df['diag_3'].str.contains('E'), ['level1_diag3', 'level2_diag3']] = 0\n",
    "df['level1_diag1'] = df['level1_diag1'].replace('?', -1)\n",
    "df['level2_diag1'] = df['level2_diag1'].replace('?', -1)\n",
    "df['level1_diag2'] = df['level1_diag2'].replace('?', -1)\n",
    "df['level2_diag2'] = df['level2_diag2'].replace('?', -1)\n",
    "df['level1_diag3'] = df['level1_diag3'].replace('?', -1)\n",
    "df['level2_diag3'] = df['level2_diag3'].replace('?', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level1_diag1'] = df['level1_diag1'].astype(float)\n",
    "df['level2_diag1'] = df['level2_diag1'].astype(float)\n",
    "df['level1_diag2'] = df['level1_diag2'].astype(float)\n",
    "df['level2_diag2'] = df['level2_diag2'].astype(float)\n",
    "df['level1_diag3'] = df['level1_diag3'].astype(float)\n",
    "df['level2_diag3'] = df['level2_diag3'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if (row['level1_diag1'] >= 390 and row['level1_diag1'] < 460) or (np.floor(row['level1_diag1']) == 785):\n",
    "        df.loc[index, 'level1_diag1'] = 1\n",
    "    elif (row['level1_diag1'] >= 460 and row['level1_diag1'] < 520) or (np.floor(row['level1_diag1']) == 786):\n",
    "        df.loc[index, 'level1_diag1'] = 2\n",
    "    elif (row['level1_diag1'] >= 520 and row['level1_diag1'] < 580) or (np.floor(row['level1_diag1']) == 787):\n",
    "        df.loc[index, 'level1_diag1'] = 3\n",
    "    elif (np.floor(row['level1_diag1']) == 250):\n",
    "        df.loc[index, 'level1_diag1'] = 4\n",
    "    elif (row['level1_diag1'] >= 800 and row['level1_diag1'] < 1000):\n",
    "        df.loc[index, 'level1_diag1'] = 5\n",
    "    elif (row['level1_diag1'] >= 710 and row['level1_diag1'] < 740):\n",
    "        df.loc[index, 'level1_diag1'] = 6\n",
    "    elif (row['level1_diag1'] >= 580 and row['level1_diag1'] < 630) or (np.floor(row['level1_diag1']) == 788):\n",
    "        df.loc[index, 'level1_diag1'] = 7\n",
    "    elif (row['level1_diag1'] >= 140 and row['level1_diag1'] < 240):\n",
    "        df.loc[index, 'level1_diag1'] = 8\n",
    "    else:\n",
    "        df.loc[index, 'level1_diag1'] = 0\n",
    "        \n",
    "    if (row['level1_diag2'] >= 390 and row['level1_diag2'] < 460) or (np.floor(row['level1_diag2']) == 785):\n",
    "        df.loc[index, 'level1_diag2'] = 1\n",
    "    elif (row['level1_diag2'] >= 460 and row['level1_diag2'] < 520) or (np.floor(row['level1_diag2']) == 786):\n",
    "        df.loc[index, 'level1_diag2'] = 2\n",
    "    elif (row['level1_diag2'] >= 520 and row['level1_diag2'] < 580) or (np.floor(row['level1_diag2']) == 787):\n",
    "        df.loc[index, 'level1_diag2'] = 3\n",
    "    elif (np.floor(row['level1_diag2']) == 250):\n",
    "        df.loc[index, 'level1_diag2'] = 4\n",
    "    elif (row['level1_diag2'] >= 800 and row['level1_diag2'] < 1000):\n",
    "        df.loc[index, 'level1_diag2'] = 5\n",
    "    elif (row['level1_diag2'] >= 710 and row['level1_diag2'] < 740):\n",
    "        df.loc[index, 'level1_diag2'] = 6\n",
    "    elif (row['level1_diag2'] >= 580 and row['level1_diag2'] < 630) or (np.floor(row['level1_diag2']) == 788):\n",
    "        df.loc[index, 'level1_diag2'] = 7\n",
    "    elif (row['level1_diag2'] >= 140 and row['level1_diag2'] < 240):\n",
    "        df.loc[index, 'level1_diag2'] = 8\n",
    "    else:\n",
    "        df.loc[index, 'level1_diag2'] = 0\n",
    "    \n",
    "    if (row['level1_diag3'] >= 390 and row['level1_diag3'] < 460) or (np.floor(row['level1_diag3']) == 785):\n",
    "        df.loc[index, 'level1_diag3'] = 1\n",
    "    elif (row['level1_diag3'] >= 460 and row['level1_diag3'] < 520) or (np.floor(row['level1_diag3']) == 786):\n",
    "        df.loc[index, 'level1_diag3'] = 2\n",
    "    elif (row['level1_diag3'] >= 520 and row['level1_diag3'] < 580) or (np.floor(row['level1_diag3']) == 787):\n",
    "        df.loc[index, 'level1_diag3'] = 3\n",
    "    elif (np.floor(row['level1_diag3']) == 250):\n",
    "        df.loc[index, 'level1_diag3'] = 4\n",
    "    elif (row['level1_diag3'] >= 800 and row['level1_diag3'] < 1000):\n",
    "        df.loc[index, 'level1_diag3'] = 5\n",
    "    elif (row['level1_diag3'] >= 710 and row['level1_diag3'] < 740):\n",
    "        df.loc[index, 'level1_diag3'] = 6\n",
    "    elif (row['level1_diag3'] >= 580 and row['level1_diag3'] < 630) or (np.floor(row['level1_diag3']) == 788):\n",
    "        df.loc[index, 'level1_diag3'] = 7\n",
    "    elif (row['level1_diag3'] >= 140 and row['level1_diag3'] < 240):\n",
    "        df.loc[index, 'level1_diag3'] = 8\n",
    "    else:\n",
    "        df.loc[index, 'level1_diag3'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if (row['level2_diag1'] >= 390 and row['level2_diag1'] < 399):\n",
    "        df.loc[index, 'level2_diag1'] = 1\n",
    "    elif (row['level2_diag1'] >= 401 and row['level2_diag1'] < 415):\n",
    "        df.loc[index, 'level2_diag1'] = 2\n",
    "    elif (row['level2_diag1'] >= 415 and row['level2_diag1'] < 460):\n",
    "        df.loc[index, 'level2_diag1'] = 3\n",
    "    elif (np.floor(row['level2_diag1']) == 785):\n",
    "        df.loc[index, 'level2_diag1'] = 4\n",
    "    elif (row['level2_diag1'] >= 460 and row['level2_diag1'] < 489):\n",
    "        df.loc[index, 'level2_diag1'] = 5\n",
    "    elif (row['level2_diag1'] >= 490 and row['level2_diag1'] < 497):\n",
    "        df.loc[index, 'level2_diag1'] = 6\n",
    "    elif (row['level2_diag1'] >= 500 and row['level2_diag1'] < 520):\n",
    "        df.loc[index, 'level2_diag1'] = 7\n",
    "    elif (np.floor(row['level2_diag1']) == 786):\n",
    "        df.loc[index, 'level2_diag1'] = 8\n",
    "    elif (row['level2_diag1'] >= 520 and row['level2_diag1'] < 530):\n",
    "        df.loc[index, 'level2_diag1'] = 9\n",
    "    elif (row['level2_diag1'] >= 530 and row['level2_diag1'] < 544):\n",
    "        df.loc[index, 'level2_diag1'] = 10\n",
    "    elif (row['level2_diag1'] >= 550 and row['level2_diag1'] < 554):\n",
    "        df.loc[index, 'level2_diag1'] = 11\n",
    "    elif (row['level2_diag1'] >= 555 and row['level2_diag1'] < 580):\n",
    "        df.loc[index, 'level2_diag1'] = 12\n",
    "    elif (np.floor(row['level2_diag1']) == 787):\n",
    "        df.loc[index, 'level2_diag1'] = 13\n",
    "    elif (np.floor(row['level2_diag1']) == 250):\n",
    "        df.loc[index, 'level2_diag1'] = 14\n",
    "    elif (row['level2_diag1'] >= 800 and row['level2_diag1'] < 1000):\n",
    "        df.loc[index, 'level2_diag1'] = 15\n",
    "    elif (row['level2_diag1'] >= 710 and row['level2_diag1'] < 740):\n",
    "        df.loc[index, 'level2_diag1'] = 16\n",
    "    elif (row['level2_diag1'] >= 580 and row['level2_diag1'] < 630):\n",
    "        df.loc[index, 'level2_diag1'] = 17\n",
    "    elif (np.floor(row['level2_diag1']) == 788):\n",
    "        df.loc[index, 'level2_diag1'] = 18\n",
    "    elif (row['level2_diag1'] >= 140 and row['level2_diag1'] < 240):\n",
    "        df.loc[index, 'level2_diag1'] = 19\n",
    "    elif row['level2_diag1'] >= 240 and row['level2_diag1'] < 280 and (np.floor(row['level2_diag1']) != 250):\n",
    "        df.loc[index, 'level2_diag1'] = 20\n",
    "    elif (row['level2_diag1'] >= 680 and row['level2_diag1'] < 710) or (np.floor(row['level2_diag1']) == 782):\n",
    "        df.loc[index, 'level2_diag1'] = 21\n",
    "    elif (row['level2_diag1'] >= 290 and row['level2_diag1'] < 320):\n",
    "        df.loc[index, 'level2_diag1'] = 22\n",
    "    else:\n",
    "        df.loc[index, 'level2_diag1'] = 0\n",
    "        \n",
    "    if (row['level2_diag2'] >= 390 and row['level2_diag2'] < 399):\n",
    "        df.loc[index, 'level2_diag2'] = 1\n",
    "    elif (row['level2_diag2'] >= 401 and row['level2_diag2'] < 415):\n",
    "        df.loc[index, 'level2_diag2'] = 2\n",
    "    elif (row['level2_diag2'] >= 415 and row['level2_diag2'] < 460):\n",
    "        df.loc[index, 'level2_diag2'] = 3\n",
    "    elif (np.floor(row['level2_diag2']) == 785):\n",
    "        df.loc[index, 'level2_diag2'] = 4\n",
    "    elif (row['level2_diag2'] >= 460 and row['level2_diag2'] < 489):\n",
    "        df.loc[index, 'level2_diag2'] = 5\n",
    "    elif (row['level2_diag2'] >= 490 and row['level2_diag2'] < 497):\n",
    "        df.loc[index, 'level2_diag2'] = 6\n",
    "    elif (row['level2_diag2'] >= 500 and row['level2_diag2'] < 520):\n",
    "        df.loc[index, 'level2_diag2'] = 7\n",
    "    elif (np.floor(row['level2_diag2']) == 786):\n",
    "        df.loc[index, 'level2_diag2'] = 8\n",
    "    elif (row['level2_diag2'] >= 520 and row['level2_diag2'] < 530):\n",
    "        df.loc[index, 'level2_diag2'] = 9\n",
    "    elif (row['level2_diag2'] >= 530 and row['level2_diag2'] < 544):\n",
    "        df.loc[index, 'level2_diag2'] = 10\n",
    "    elif (row['level2_diag2'] >= 550 and row['level2_diag2'] < 554):\n",
    "        df.loc[index, 'level2_diag2'] = 11\n",
    "    elif (row['level2_diag2'] >= 555 and row['level2_diag2'] < 580):\n",
    "        df.loc[index, 'level2_diag2'] = 12\n",
    "    elif (np.floor(row['level2_diag2']) == 787):\n",
    "        df.loc[index, 'level2_diag2'] = 13\n",
    "    elif (np.floor(row['level2_diag2']) == 250):\n",
    "        df.loc[index, 'level2_diag2'] = 14\n",
    "    elif (row['level2_diag2'] >= 800 and row['level2_diag2'] < 1000):\n",
    "        df.loc[index, 'level2_diag2'] = 15\n",
    "    elif (row['level2_diag2'] >= 710 and row['level2_diag2'] < 740):\n",
    "        df.loc[index, 'level2_diag2'] = 16\n",
    "    elif (row['level2_diag2'] >= 580 and row['level2_diag2'] < 630):\n",
    "        df.loc[index, 'level2_diag2'] = 17\n",
    "    elif (np.floor(row['level2_diag2']) == 788):\n",
    "        df.loc[index, 'level2_diag2'] = 18\n",
    "    elif (row['level2_diag2'] >= 140 and row['level2_diag2'] < 240):\n",
    "        df.loc[index, 'level2_diag2'] = 19\n",
    "    elif row['level2_diag2'] >= 240 and row['level2_diag2'] < 280 and (np.floor(row['level2_diag2']) != 250):\n",
    "        df.loc[index, 'level2_diag2'] = 20\n",
    "    elif (row['level2_diag2'] >= 680 and row['level2_diag2'] < 710) or (np.floor(row['level2_diag2']) == 782):\n",
    "        df.loc[index, 'level2_diag2'] = 21\n",
    "    elif (row['level2_diag2'] >= 290 and row['level2_diag2'] < 320):\n",
    "        df.loc[index, 'level2_diag2'] = 22\n",
    "    else:\n",
    "        df.loc[index, 'level2_diag2'] = 0\n",
    "        \n",
    "        \n",
    "    if (row['level2_diag3'] >= 390 and row['level2_diag3'] < 399):\n",
    "        df.loc[index, 'level2_diag3'] = 1\n",
    "    elif (row['level2_diag3'] >= 401 and row['level2_diag3'] < 415):\n",
    "        df.loc[index, 'level2_diag3'] = 2\n",
    "    elif (row['level2_diag3'] >= 415 and row['level2_diag3'] < 460):\n",
    "        df.loc[index, 'level2_diag3'] = 3\n",
    "    elif (np.floor(row['level2_diag3']) == 785):\n",
    "        df.loc[index, 'level2_diag3'] = 4\n",
    "    elif (row['level2_diag3'] >= 460 and row['level2_diag3'] < 489):\n",
    "        df.loc[index, 'level2_diag3'] = 5\n",
    "    elif (row['level2_diag3'] >= 490 and row['level2_diag3'] < 497):\n",
    "        df.loc[index, 'level2_diag3'] = 6\n",
    "    elif (row['level2_diag3'] >= 500 and row['level2_diag3'] < 520):\n",
    "        df.loc[index, 'level2_diag3'] = 7\n",
    "    elif (np.floor(row['level2_diag3']) == 786):\n",
    "        df.loc[index, 'level2_diag3'] = 8\n",
    "    elif (row['level2_diag3'] >= 520 and row['level2_diag3'] < 530):\n",
    "        df.loc[index, 'level2_diag3'] = 9\n",
    "    elif (row['level2_diag3'] >= 530 and row['level2_diag3'] < 544):\n",
    "        df.loc[index, 'level2_diag3'] = 10\n",
    "    elif (row['level2_diag3'] >= 550 and row['level2_diag3'] < 554):\n",
    "        df.loc[index, 'level2_diag3'] = 11\n",
    "    elif (row['level2_diag3'] >= 555 and row['level2_diag3'] < 580):\n",
    "        df.loc[index, 'level2_diag3'] = 12\n",
    "    elif (np.floor(row['level2_diag3']) == 787):\n",
    "        df.loc[index, 'level2_diag3'] = 13\n",
    "    elif (np.floor(row['level2_diag3']) == 250):\n",
    "        df.loc[index, 'level2_diag3'] = 14\n",
    "    elif (row['level2_diag3'] >= 800 and row['level2_diag3'] < 1000):\n",
    "        df.loc[index, 'level2_diag3'] = 15\n",
    "    elif (row['level2_diag3'] >= 710 and row['level2_diag3'] < 740):\n",
    "        df.loc[index, 'level2_diag3'] = 16\n",
    "    elif (row['level2_diag3'] >= 580 and row['level2_diag3'] < 630):\n",
    "        df.loc[index, 'level2_diag3'] = 17\n",
    "    elif (np.floor(row['level2_diag3']) == 788):\n",
    "        df.loc[index, 'level2_diag3'] = 18\n",
    "    elif (row['level2_diag3'] >= 140 and row['level2_diag3'] < 240):\n",
    "        df.loc[index, 'level2_diag3'] = 19\n",
    "    elif row['level2_diag3'] >= 240 and row['level2_diag3'] < 280 and (np.floor(row['level2_diag3']) != 250):\n",
    "        df.loc[index, 'level2_diag3'] = 20\n",
    "    elif (row['level2_diag3'] >= 680 and row['level2_diag3'] < 710) or (np.floor(row['level2_diag3']) == 782):\n",
    "        df.loc[index, 'level2_diag3'] = 21\n",
    "    elif (row['level2_diag3'] >= 290 and row['level2_diag3'] < 320):\n",
    "        df.loc[index, 'level2_diag3'] = 22\n",
    "    else:\n",
    "        df.loc[index, 'level2_diag3'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of Readmission\n",
    "Our target variable is imbalance. Number of readmitted patient are quite less as compared to Not readmitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Readmission \n",
    "sns.countplot(df['readmitted']).set_title('Distrinution of Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time in Hospital and Readmission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,7),)\n",
    "ax=sns.kdeplot(df.loc[(df['readmitted'] == 0),'time_in_hospital'] , color='b',shade=True,label='Not Readmitted')\n",
    "ax=sns.kdeplot(df.loc[(df['readmitted'] == 1),'time_in_hospital'] , color='r',shade=True, label='Readmitted')\n",
    "ax.set(xlabel='Time in Hospital', ylabel='Frequency')\n",
    "plt.title('Time in Hospital VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age and Readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "sns.countplot(y= df['age'], hue = df['readmitted']).set_title('Age of Patient VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethnicity of patient and Readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.countplot(y = df['race'], hue = df['readmitted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of medication used and Readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.barplot(x = df['readmitted'], y = df['num_medications']).set_title(\"Number of medication used VS. Readmission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender and Readmission\n",
    "* Male = 1\n",
    "* Female = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.countplot(df['gender'], hue = df['readmitted']).set_title(\"Gender of Patient VS. Readmission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change of Medication and Readmission\n",
    "* Change = 1\n",
    "* No Change = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.countplot(df['change'], hue = df['readmitted']).set_title('Change of Medication VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diabetes Medication prescribed and Readmission\n",
    "* Diabetes Medication - medications Nominal Indicates if there was any diabetic medication prescribed.\n",
    "* Values: “yes” : 1 “no” : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.countplot(df['diabetesMed'], hue = df['readmitted']).set_title('Diabetes Medication prescribed VS Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Service Utilization and Readmission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.barplot( y = df['service_utilization'], x = df['readmitted']).set_title('Service Utilization VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glucose serum test result and Readmission\n",
    "*Glucose Serum test* - A blood glucose test is used to find out if your blood sugar levels are in the healthy range. It is often used to help diagnose and monitor diabetes.\n",
    "\n",
    "* '>200' : 1 = indicates diabetes\n",
    "* '>300' : 1 = Indicates diabetes\n",
    "* 'Norm' : 0 = Normal\n",
    "* 'None' : -99 = test was not taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.countplot(y = df['max_glu_serum'], hue = df['readmitted']).set_title('Glucose test serum test result VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1C result and Readmission\n",
    "*A1C test* - The A1C test is a blood test that provides information about your average levels of blood glucose, also called blood sugar, over the past 3 months.\n",
    "*  '>7'   :  1   \n",
    "*  '>8'   :  1   \n",
    "*    Norm :  0  = Normal \n",
    "*    None : -99 = Test was not taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.countplot(y= df['A1Cresult'], hue = df['readmitted']).set_title('A1C test result VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of lab procedure and Readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6),)\n",
    "ax=sns.kdeplot(df.loc[(df['readmitted'] == 0),'num_lab_procedures'] , color='b',shade=True,label='Not readmitted')\n",
    "ax=sns.kdeplot(df.loc[(df['readmitted'] == 1),'num_lab_procedures'] , color='r',shade=True, label='readmitted')\n",
    "ax.set(xlabel='Number of lab procedure', ylabel='Frequency')\n",
    "plt.title('Number of lab procedure VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Modeling Data Preprocessing\n",
    "This code converts age as categorical variable to a continuous approximation by assuming mid-point of each age-category as the actual age value. This is done to avoid having to deal with age as a dummy variable in the models which makes interpretation very cumbersome. Also, since age category is not purely nominal but ordinal, we do not want to lose that information by treating it as a simple categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].astype('int64')\n",
    "print(df.age.value_counts())\n",
    "# convert age categories to mid-point values\n",
    "age_dict = {1:5, 2:15, 3:25, 4:35, 5:45, 6:55, 7:65, 8:75, 9:85, 10:95}\n",
    "df['age'] = df.age.map(age_dict)\n",
    "print(df.age.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data type of nominal features in dataframe to 'object' type\n",
    "i = ['encounter_id', 'patient_nbr', 'gender', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\\\n",
    "          'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \\\n",
    "          'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose','miglitol', \\\n",
    "          'troglitazone', 'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin', \\\n",
    "          'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed', \\\n",
    "          'age', 'A1Cresult', 'max_glu_serum', 'level1_diag1', 'level1_diag2', 'level1_diag3', 'level2_diag1', 'level2_diag2', 'level2_diag3']\n",
    "\n",
    "for tmp in i:\n",
    "    df[tmp] = df[tmp].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of medication used: Another possibly related factor could be the total number of medications used by the patient (which may indicate severity of their condition and/or the intensity of care). So we created another feature by counting the medications used during the encounter (keys variable in code below is continued from above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nummed'] = 0\n",
    "\n",
    "for col in keys:\n",
    "    df['nummed'] = df['nummed'] + df[col]\n",
    "df['nummed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of only numeric features\n",
    "num_col = list(set(list(df._get_numeric_data().columns))- {'readmitted'})\n",
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing skewnewss and kurtosis using log transformation if it is above a threshold value -  2\n",
    "\n",
    "statdataframe = pd.DataFrame()\n",
    "statdataframe['numeric_column'] = num_col\n",
    "skew_before = []\n",
    "skew_after = []\n",
    "\n",
    "kurt_before = []\n",
    "kurt_after = []\n",
    "\n",
    "standard_deviation_before = []\n",
    "standard_deviation_after = []\n",
    "\n",
    "log_transform_needed = []\n",
    "\n",
    "log_type = []\n",
    "\n",
    "for i in num_col:\n",
    "    skewval = df[i].skew()\n",
    "    skew_before.append(skewval)\n",
    "    \n",
    "    kurtval = df[i].kurtosis()\n",
    "    kurt_before.append(kurtval)\n",
    "    \n",
    "    sdval = df[i].std()\n",
    "    standard_deviation_before.append(sdval)\n",
    "    \n",
    "    if (abs(skewval) >2) & (abs(kurtval) >2):\n",
    "        log_transform_needed.append('Yes')\n",
    "        \n",
    "        if len(df[df[i] == 0])/len(df) <=0.02:\n",
    "            log_type.append('log')\n",
    "            skewvalnew = np.log(pd.DataFrame(df[train_data[i] > 0])[i]).skew()\n",
    "            skew_after.append(skewvalnew)\n",
    "            \n",
    "            kurtvalnew = np.log(pd.DataFrame(df[train_data[i] > 0])[i]).kurtosis()\n",
    "            kurt_after.append(kurtvalnew)\n",
    "            \n",
    "            sdvalnew = np.log(pd.DataFrame(df[train_data[i] > 0])[i]).std()\n",
    "            standard_deviation_after.append(sdvalnew)\n",
    "            \n",
    "        else:\n",
    "            log_type.append('log1p')\n",
    "            skewvalnew = np.log1p(pd.DataFrame(df[df[i] >= 0])[i]).skew()\n",
    "            skew_after.append(skewvalnew)\n",
    "        \n",
    "            kurtvalnew = np.log1p(pd.DataFrame(df[df[i] >= 0])[i]).kurtosis()\n",
    "            kurt_after.append(kurtvalnew)\n",
    "            \n",
    "            sdvalnew = np.log1p(pd.DataFrame(df[df[i] >= 0])[i]).std()\n",
    "            standard_deviation_after.append(sdvalnew)\n",
    "            \n",
    "    else:\n",
    "        log_type.append('NA')\n",
    "        log_transform_needed.append('No')\n",
    "        \n",
    "        skew_after.append(skewval)\n",
    "        kurt_after.append(kurtval)\n",
    "        standard_deviation_after.append(sdval)\n",
    "\n",
    "statdataframe['skew_before'] = skew_before\n",
    "statdataframe['kurtosis_before'] = kurt_before\n",
    "statdataframe['standard_deviation_before'] = standard_deviation_before\n",
    "statdataframe['log_transform_needed'] = log_transform_needed\n",
    "statdataframe['log_type'] = log_type\n",
    "statdataframe['skew_after'] = skew_after\n",
    "statdataframe['kurtosis_after'] = kurt_after\n",
    "statdataframe['standard_deviation_after'] = standard_deviation_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statdataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the log transformation for the columns determined to be needing it above.\n",
    "\n",
    "for i in range(len(statdataframe)):\n",
    "    if statdataframe['log_transform_needed'][i] == 'Yes':\n",
    "        colname = str(statdataframe['numeric_column'][i])\n",
    "        \n",
    "        if statdataframe['log_type'][i] == 'log':\n",
    "            df = df[df[colname] > 0]\n",
    "            df[colname + \"_log\"] = np.log(df[colname])\n",
    "            \n",
    "        elif statdataframe['log_type'][i] == 'log1p':\n",
    "            df = df[df[colname] >= 0]\n",
    "            df[colname + \"_log1p\"] = np.log1p(df[colname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['number_outpatient', 'number_inpatient', 'number_emergency','service_utilization'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of only numeric features\n",
    "numerics = list(set(list(df._get_numeric_data().columns))- {'readmitted'})\n",
    "numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show list of features that are categorical\n",
    "df.encounter_id = df.encounter_id.astype('int64')\n",
    "df.patient_nbr = df.patient_nbr.astype('int64')\n",
    "df.diabetesMed = df.diabetesMed.astype('int64')\n",
    "df.change = df.change.astype('int64')\n",
    "\n",
    "# convert data type of nominal features in dataframe to 'object' type for aggregating\n",
    "i = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \\\n",
    "          'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose','miglitol', \\\n",
    "          'troglitazone', 'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin', \\\n",
    "          'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone','A1Cresult']\n",
    "df[i] = df[i].astype('int64')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcopy = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'] = df['readmitted'].apply(lambda x: 0 if x == 2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop individual diagnosis columns that have too granular disease information\n",
    "# also drop level 2 categorization (which was not comparable with any reference)\n",
    "# also drop level 1 secondary and tertiary diagnoses\n",
    "df.drop(['diag_1', 'diag_2', 'diag_3', 'level2_diag1', 'level1_diag2', 'level2_diag2', 'level1_diag3',\n",
    "         'level2_diag3'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactionterms = [('num_medications','time_in_hospital'),\n",
    "('num_medications','num_procedures'),\n",
    "('time_in_hospital','num_lab_procedures'),\n",
    "('num_medications','num_lab_procedures'),\n",
    "('num_medications','number_diagnoses'),\n",
    "('age','number_diagnoses'),\n",
    "('change','num_medications'),\n",
    "('number_diagnoses','time_in_hospital'),\n",
    "('num_medications','numchange')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inter in interactionterms:\n",
    "    name = inter[0] + '|' + inter[1]\n",
    "    df[name] = df[inter[0]] * df[inter[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['num_medications','time_in_hospital', 'num_medications|time_in_hospital']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "datf = pd.DataFrame()\n",
    "datf['features'] = numerics\n",
    "datf['std_dev'] = datf['features'].apply(lambda x: df[x].std())\n",
    "datf['mean'] = datf['features'].apply(lambda x: df[x].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping multiple encounters while keeping either first or last encounter of these patients\n",
    "df2 = df.drop_duplicates(subset= ['patient_nbr'], keep = 'first')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize function\n",
    "def standardize(raw_data):\n",
    "    return ((raw_data - np.mean(raw_data, axis = 0)) / np.std(raw_data, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[numerics] = standardize(df2[numerics])\n",
    "import scipy as sp\n",
    "df2 = df2[(np.abs(sp.stats.zscore(df2[numerics])) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "my_cmap = ListedColormap(sns.light_palette((250, 100, 50), input=\"husl\", n_colors=50).as_hex())\n",
    "table = df2.drop(['patient_nbr', 'encounter_id'], axis=1).corr(method='pearson')\n",
    "table.style.background_gradient(cmap=my_cmap, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['level1_diag1'] = df2['level1_diag1'].astype('object')\n",
    "df_pd = pd.get_dummies(df2, columns=['gender', 'admission_type_id', 'discharge_disposition_id',\n",
    "                                      'admission_source_id', 'max_glu_serum', 'A1Cresult', 'level1_diag1'], drop_first = True)\n",
    "just_dummies = pd.get_dummies(df_pd['race'])\n",
    "df_pd = pd.concat([df_pd, just_dummies], axis=1)      \n",
    "df_pd.drop(['race'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_num_cols = ['race', 'gender', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', \n",
    "                'max_glu_serum', 'A1Cresult', 'level1_diag1' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = list(set(list(df._get_numeric_data().columns))- {'readmitted', 'change'})\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_non_num_cols = []\n",
    "for i in non_num_cols:\n",
    "    for j in df_pd.columns:\n",
    "        if i in j:\n",
    "            new_non_num_cols.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_non_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for feature in list(df_pd.columns):\n",
    "    if '|' in feature:\n",
    "        l.append(feature)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = ['age', 'time_in_hospital', 'num_procedures', 'num_medications', 'number_outpatient_log1p', \n",
    "                 'number_emergency_log1p', 'number_inpatient_log1p', 'number_diagnoses', 'metformin', \n",
    "                 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n",
    "                 'pioglitazone', 'rosiglitazone', 'acarbose', 'tolazamide', 'insulin', 'glyburide-metformin',\n",
    "                 'AfricanAmerican', 'Asian', 'Caucasian', 'Hispanic', 'Other', 'gender_1', \n",
    "                 'admission_type_id_3', 'admission_type_id_5', 'discharge_disposition_id_2', 'discharge_disposition_id_7', \n",
    "                 'discharge_disposition_id_10', 'discharge_disposition_id_18', 'admission_source_id_4',\n",
    "                 'admission_source_id_7', 'admission_source_id_9', 'max_glu_serum_0', 'max_glu_serum_1', 'A1Cresult_0',\n",
    "                 'A1Cresult_1', 'num_medications|time_in_hospital', 'num_medications|num_procedures',\n",
    "                 'time_in_hospital|num_lab_procedures', 'num_medications|num_lab_procedures', 'num_medications|number_diagnoses',\n",
    "                 'age|number_diagnoses', 'change|num_medications', 'number_diagnoses|time_in_hospital',\n",
    "                 'num_medications|numchange', 'level1_diag1_1.0', 'level1_diag1_2.0', 'level1_diag1_3.0', 'level1_diag1_4.0',\n",
    "                 'level1_diag1_5.0','level1_diag1_6.0', 'level1_diag1_7.0', 'level1_diag1_8.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pd[feature_set]\n",
    "y = df_pd['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('diabetic_data.npz', X=X, y=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
